# Reflection on Prompt Engineering

Working on this project gave me a hands-on understanding of how system prompts influence the behavior of conversational AI. By experimenting with three distinct personas—Professional, Creative, and Technical—I observed how small changes in prompt wording could drastically affect tone, clarity, and depth of responses.

For example, the Creative persona produced playful storytelling outputs, often personifying plants and using analogies. This made explanations engaging but less technical. The Technical persona, on the other hand, gave structured, step-by-step explanations with equations and detailed processes, which is highly effective for educational or expert settings but may overwhelm non-technical users. Interestingly, the Professional persona drifted into a creative tone, which highlighted that vague or loosely written system prompts can cause the AI to misinterpret the intended style.

From this, I learned that prompt engineering is not just about instructions, but also about constraints. Adding clear requirements such as response length, tone, or structure (e.g., bullet points, analogies, or step-by-step format) helps guide the model toward more predictable and consistent behavior.

This exercise also reinforced the value of rubric-based evaluation. Scoring prompts across clarity, specificity, consistency, and effectiveness provided a structured way to measure performance and identify gaps. In real-world applications, this approach can help design role-based AI assistants for customer service, education, or creative writing without retraining the underlying model.

Overall, this project strengthened my understanding of prompt design as a powerful tool for controlling AI outputs and tailoring them to different user needs.
